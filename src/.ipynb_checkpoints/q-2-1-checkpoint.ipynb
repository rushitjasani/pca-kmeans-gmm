{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rushit/.local/lib/python2.7/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input_data/AdmissionDataset/data.csv\")\n",
    "threshold = 0.5\n",
    "df.loc[df['Chance of Admit ']<threshold,'Chance of Admit '] = 0\n",
    "df.loc[df['Chance of Admit ']>=threshold,'Chance of Admit '] = 1\n",
    "X = df.drop(['Serial No.','Chance of Admit '],axis=1)\n",
    "Y = df['Chance of Admit ']\n",
    "\n",
    "col_names = [i for i in X]\n",
    "X = pd.DataFrame(preprocessing.scale(X), columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train,Y_train)\n",
    "pred = regressor.predict(X_test) \n",
    "print(regressor.coef_)\n",
    "print(regressor.intercept_)\n",
    "r2_score(Y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [ 1 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.25      0.36         8\n",
      "         1.0       0.93      0.99      0.96        82\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        90\n",
      "   macro avg       0.80      0.62      0.66        90\n",
      "weighted avg       0.91      0.92      0.91        90\n",
      "\n",
      "0.9222222222222223\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "logreg.fit(X_train, Y_train)\n",
    "Z = logreg.predict(X_test)\n",
    "print confusion_matrix(Y_test,Z)\n",
    "print classification_report(Y_test,Z)\n",
    "print accuracy_score(Y_test,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train.reset_index(drop=True)\n",
    "Y_train1 = Y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = pd.DataFrame(1,index=np.arange(X_train.shape[0]),columns=[\"ones\"])\n",
    "X_train1 = pd.concat([ones, X_train1],axis=1)\n",
    "X_train1 = np.array(X_train1)\n",
    "Y_train1 = np.array(Y_train1).reshape(X_train1.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros([1,8])\n",
    "alpha = 0.01\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(X):\n",
    "    X=-X\n",
    "    return 1/(1+np.exp(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X,Y,theta,it,alpha):\n",
    "    for i in range(it):\n",
    "        theta = theta - (alpha) * np.sum(X * (h(np.matmul(X, theta.T)) - Y), axis=0)\n",
    "    return theta\n",
    "\n",
    "g = gradientDescent(X_train1,Y_train1,theta,iterations,alpha)\n",
    "theta_list = g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test):\n",
    "    Y_pred=[]\n",
    "    for index,row in X_test.iterrows():\n",
    "        row=list(row)\n",
    "        y1=0\n",
    "        for i in range(1,8):\n",
    "            y1=y1+theta_list[i]*row[i-1]\n",
    "        y1=y1+theta_list[0]\n",
    "        Y_pred.append(0 if y1<0.5 else 1)\n",
    "    return Y_pred\n",
    "pred = predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  5]\n",
      " [ 2 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.38      0.46         8\n",
      "         1.0       0.94      0.98      0.96        82\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        90\n",
      "   macro avg       0.77      0.68      0.71        90\n",
      "weighted avg       0.91      0.92      0.91        90\n",
      "\n",
      "0.9222222222222223\n"
     ]
    }
   ],
   "source": [
    "# print r2_score(list(Y_test),pred)\n",
    "# print theta_list\n",
    "\n",
    "print confusion_matrix(Y_test,pred)\n",
    "print classification_report(Y_test,pred)\n",
    "print accuracy_score(Y_test,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
